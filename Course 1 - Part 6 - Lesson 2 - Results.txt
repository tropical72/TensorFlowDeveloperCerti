Try editing the convolutions. Change the 32s to either 16 or 64. What impact will this have on accuracy and/or training time.
=> more convolution results in better accuracy. but more time in the first epch.

Remove the final Convolution. What impact will this have on accuracy or training time?
=> Data increases to flatten. More time in the first epoch. Better accuracy.

How about adding more Convolutions? What impact do you think this will have? Experiment with it.
=> Does not work for increasing accuracy. But reduces data to Dense 

Remove all Convolutions but the first. What impact do you think this will have? Experiment with it.
=> Increases accuracy. increases data to flatten.

In the previous lesson you implemented a callback to check on the loss function and to cancel training once it hit a certain amount. See if you can implement that here!
=> it works.


conv 64
_________________________________________________________________
Epoch 1/5
1875/1875 [==============================] - 10s 2ms/step - loss: 0.6100 - accuracy: 0.7787
Epoch 2/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.3155 - accuracy: 0.8844
Epoch 3/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.2618 - accuracy: 0.9027
Epoch 4/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.2223 - accuracy: 0.9168
Epoch 5/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.1927 - accuracy: 0.926



2 conv 32 (GPU)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_13 (Conv2D)           (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d_12 (MaxPooling (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 11, 11, 32)        9248      
_________________________________________________________________
max_pooling2d_13 (MaxPooling (None, 5, 5, 32)          0         
_________________________________________________________________
flatten_8 (Flatten)          (None, 800)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 128)               102528    
_________________________________________________________________
dense_17 (Dense)             (None, 10)                1290      
=================================================================
Total params: 113,386
Trainable params: 113,386
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
1875/1875 [==============================] - 5s 2ms/step - loss: 0.6522 - accuracy: 0.7657
Epoch 2/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.3323 - accuracy: 0.8797
Epoch 3/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.2768 - accuracy: 0.8992
Epoch 4/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.2500 - accuracy: 0.9074
Epoch 5/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.2218 - accuracy: 0.9176
313/313 [==============================] - 1s 2ms/step - loss: 0.2722 - accuracy: 0.9008


2 conv 32 (CPU) : GPU보다 8~9배 느림!!!!
_________________________________________________________________
Epoch 1/5
1875/1875 [==============================] - 37s 19ms/step - loss: 0.6452 - accuracy: 0.7674
Epoch 2/5
1875/1875 [==============================] - 36s 19ms/step - loss: 0.3204 - accuracy: 0.8832
Epoch 3/5
1875/1875 [==============================] - 36s 19ms/step - loss: 0.2806 - accuracy: 0.8980
Epoch 4/5
1875/1875 [==============================] - 35s 19ms/step - loss: 0.2439 - accuracy: 0.9092
Epoch 5/5
1875/1875 [==============================] - 35s 19ms/step - loss: 0.2200 - accuracy: 0.9184
313/313 [==============================] - 2s 6ms/step - loss: 0.2678 - accuracy: 0.9031


1 conv 32 (GPU) : 
* convolution layer 를 1개 했을때, 2개때 보다 정확도가 높아짐.
* 전체 수행시간은 차이가 없으나  flatten을 보면 메모리를 더 사용하는 것이 확인되고 이것이 conv를 적게할 때의 단점이라보 봐야할듯. 
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_12 (Conv2D)           (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d_11 (MaxPooling (None, 13, 13, 32)        0         
_________________________________________________________________
flatten_7 (Flatten)          (None, 5408)              0         
_________________________________________________________________
dense_14 (Dense)             (None, 128)               692352    
_________________________________________________________________
dense_15 (Dense)             (None, 10)                1290      
=================================================================
Total params: 693,962
Trainable params: 693,962
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.5140 - accuracy: 0.8211
Epoch 2/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.2697 - accuracy: 0.9029
Epoch 3/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.2179 - accuracy: 0.9206
Epoch 4/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.1811 - accuracy: 0.9343
Epoch 5/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.1504 - accuracy: 0.9442
313/313 [==============================] - 1s 2ms/step - loss: 0.2640 - accuracy: 0.9085


[3 conv 32(GPU)]
* 전체 정확도는 떨어짐. 이것은 max pooling을 하면서 데이터가 너무 작아져서 오히려 content분석의 정확도가 떨어진 것으로 보임
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_15 (Conv2D)           (None, 26, 26, 32)        320       
_________________________________________________________________
max_pooling2d_14 (MaxPooling (None, 13, 13, 32)        0         
_________________________________________________________________
conv2d_16 (Conv2D)           (None, 11, 11, 32)        9248      
_________________________________________________________________
max_pooling2d_15 (MaxPooling (None, 5, 5, 32)          0         
_________________________________________________________________
conv2d_17 (Conv2D)           (None, 3, 3, 32)          9248      
_________________________________________________________________
max_pooling2d_16 (MaxPooling (None, 1, 1, 32)          0         
_________________________________________________________________
flatten_9 (Flatten)          (None, 32)                0         
_________________________________________________________________
dense_18 (Dense)             (None, 128)               4224      
_________________________________________________________________
dense_19 (Dense)             (None, 10)                1290      
=================================================================
Total params: 24,330
Trainable params: 24,330
Non-trainable params: 0
_________________________________________________________________
Epoch 1/5
1875/1875 [==============================] - 5s 2ms/step - loss: 0.8769 - accuracy: 0.6727
Epoch 2/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.4793 - accuracy: 0.8234
Epoch 3/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.3977 - accuracy: 0.8542
Epoch 4/5
1875/1875 [==============================] - 5s 2ms/step - loss: 0.3567 - accuracy: 0.8678
Epoch 5/5
1875/1875 [==============================] - 4s 2ms/step - loss: 0.3339 - accuracy: 0.8777
313/313 [==============================] - 1s 2ms/step - loss: 0.3705 - accuracy: 0.8658

